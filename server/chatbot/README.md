# Чатбот для виртуального музея

Виртуальный ассистент для музея, использующий GigaChat и LangChain для генерации ответов на вопросы посетителей.

## Возможности

- Интеллектуальный поиск экспонатов и исторических личностей
- RAG (Retrieval-Augmented Generation) для точных ответов
- История диалога
- Автоматическое извлечение ссылок на экспонаты в ответах

## Настройка

### 1. Установка зависимостей

Убедитесь, что установлены все зависимости из `pyproject.toml`:

```bash
poetry install
```

Основные зависимости для чатбота:
- `langchain` - фреймворк для работы с LLM
- `langchain-community` - интеграция с различными LLM провайдерами
- `gigachat` - клиент для работы с GigaChat API

### 2. Настройка переменных окружения

Добавьте следующие переменные в файл `.env` (в корне проекта `server/`):

```env
# GigaChat credentials
GIGACHAT_AUTH_KEY=Basic YOUR_AUTH_KEY_HERE
SCOPE=GIGACHAT_API_PERS
GIGACHAT_VERIFY_SSL_CERTS=True
```

Где получить `GIGACHAT_AUTH_KEY`:
1. Зарегистрируйтесь на https://developers.sber.ru/
2. Создайте приложение и получите авторизационные данные
3. Используйте формат: `Basic <base64_encoded_credentials>`

### 3. Миграции базы данных

Примените миграции для создания таблиц чатбота:

```bash
python manage.py migrate chatbot
```

## API Endpoints

### Отправка сообщения

**POST** `/api/chatbot/message/`

Запрос:
```json
{
  "message": "Расскажи об экспонатах музея",
  "session_id": "optional-session-id"
}
```

Ответ:
```json
{
  "message": "В нашем музее представлены различные экспонаты...",
  "session_id": "uuid-session-id",
  "links": [
    {
      "type": "artifact",
      "id": 1,
      "name": "Название экспоната",
      "url": "/artifacts/1"
    }
  ]
}
```

### Получение истории сессии

**GET** `/api/chatbot/session/{session_id}/`

Ответ:
```json
{
  "id": 1,
  "session_id": "uuid-session-id",
  "created_at": "2024-01-01T00:00:00Z",
  "updated_at": "2024-01-01T00:00:00Z",
  "messages": [
    {
      "id": 1,
      "role": "user",
      "content": "Привет",
      "created_at": "2024-01-01T00:00:00Z"
    },
    {
      "id": 2,
      "role": "bot",
      "content": "Здравствуйте!",
      "created_at": "2024-01-01T00:00:01Z"
    }
  ]
}
```

### Создание новой сессии

**POST** `/api/chatbot/session/`

Ответ:
```json
{
  "id": 1,
  "session_id": "uuid-session-id",
  "created_at": "2024-01-01T00:00:00Z",
  "updated_at": "2024-01-01T00:00:00Z",
  "messages": []
}
```

## Архитектура

### Компоненты

1. **llm_service.py** - Сервис для работы с GigaChat через LangChain
2. **search_service.py** - Сервис для поиска экспонатов и исторических личностей (RAG)
3. **prompts.py** - Промпты для LLM с инструкциями для виртуального гида
4. **views.py** - API endpoints для работы с чатом
5. **models.py** - Модели для хранения сессий и сообщений

### Промпт-инжиниринг

Системный промпт включает:
- Роль: цифровой гид музея
- Возможности: рассказ об экспонатах, исторических личностях, залах
- Формат ответов: Markdown с ссылками на экспонаты
- Контекстная информация из базы данных

### RAG (Retrieval-Augmented Generation)

При каждом запросе:
1. Система ищет релевантные экспонаты и исторические личности в БД
2. Формируется контекст с информацией о найденных объектах
3. Контекст передается в LLM вместе с промптом
4. LLM генерирует ответ на основе контекста и истории диалога

## Разработка

### Тестирование

Для тестирования API можно использовать curl:

```bash
curl -X POST http://localhost:8000/api/chatbot/message/ \
  -H "Content-Type: application/json" \
  -d '{"message": "Привет"}'
```

Или через Swagger UI:
http://localhost:8000/api/docs/

### Отладка

Логи ошибок выводятся в консоль Django. При проблемах с GigaChat проверьте:
- Правильность `GIGACHAT_AUTH_KEY`
- Доступность API GigaChat
- Наличие установленных зависимостей

## Возможные улучшения

- Векторный поиск для более точного поиска экспонатов
- Кэширование ответов для часто задаваемых вопросов
- Поддержка нескольких языков
- Интеграция с другими LLM провайдерами
- Аналитика популярных вопросов
